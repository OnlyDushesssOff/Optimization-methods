import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from scipy.optimize import differential_evolution, minimize
from scipy import integrate
import pickle
import csv
import os

# =============================================================================
# –ë–õ–û–ö 1: –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ò –ü–ê–†–ê–ú–ï–¢–†–´
# =============================================================================

class Config:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
    D = 100  # –≥–ª—É–±–∏–Ω–∞ –≤–æ–¥–æ—ë–º–∞
    GRAYZONE_MIN = 5
    GRAYZONE_MAX = 20
    T_POINTS = 500  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—á–µ–∫ –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–∏—è

# =============================================================================
# –ë–õ–û–ö 2: –ì–ï–ù–ï–†–ê–¶–ò–Ø –°–†–ï–î–´
# =============================================================================

def generate_environment():
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å—Ä–µ–¥—ã –∏ –æ—Ä–≥–∞–Ω–∏–∑–º–∞
    """
    env = {
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å—Ä–µ–¥—ã
        "sigma1": np.random.uniform(0.25, 8.61),
        "xi1": np.random.uniform(0.025, 9.18),
        "sigma2": np.random.uniform(0.003, 8.99),
        "xi2": np.random.uniform(0.025, 9.18),
        "xi3": np.random.uniform(0.025, 9.18),
        "xi4": np.random.uniform(0.5, 1.0),
        "eta1": np.random.uniform(0.05, 0.2),
        "eta2": np.random.uniform(0.05, 0.2),
        "c3": np.random.uniform(-20, -5),
        "c4": np.random.uniform(-90, -60),

        # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –æ—Ä–≥–∞–Ω–∏–∑–º–∞ (—Ç–µ–ø–µ—Ä—å –æ–Ω–∏ –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è, –Ω–æ –Ω–µ –±—É–¥—É—Ç –≤ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö)
        "a": np.random.uniform(0.1, 1000),
        "gamma": np.random.uniform(0.001, 1000),
        "beta": np.random.uniform(1e-9, 0.001),
        "lambda_Q": np.random.uniform(1e-5, 1000),

        # –ì—Ä–∞–Ω–∏—Ü—ã —Å–µ—Ä–æ–π –∑–æ–Ω—ã
        "grayzone_min": Config.GRAYZONE_MIN,
        "grayzone_max": Config.GRAYZONE_MAX
    }
    return env

# =============================================================================
# –ë–õ–û–ö 3: –§–£–ù–ö–¶–ò–ò –°–†–ï–î–´ –ò –¢–†–ê–ï–ö–¢–û–†–ò–ò
# =============================================================================

def E(x, env_params):
    """–§—É–Ω–∫—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –µ–¥—ã"""
    norm_x = (x + Config.D/2) / Config.D
    return env_params["sigma1"] * (1 + np.tanh(env_params["xi1"] * norm_x))

def P_x(x, env_params):
    """–ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ —Ä–∏—Å–∫–∞"""
    norm_x = (x + Config.D/2) / Config.D
    return env_params["sigma2"] * (1 + np.tanh(env_params["xi2"] * norm_x))

def P_t(t, sigma_2=2.0):
    """–í—Ä–µ–º–µ–Ω–Ω–∞—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ —Ä–∏—Å–∫–∞"""
    return sigma_2 * (-0.5 * np.cos(2 * np.pi * t) + 0.5)

def Q(x, env_params):
    """–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å—Ä–µ–¥—ã"""
    return (env_params["xi3"] * np.exp(env_params["eta1"] * (x - env_params["c3"])) +
            env_params["xi4"] * np.exp(-env_params["eta2"] * (x - env_params["c4"]))) / 2

def x_trajectory(t, A, b):
    """–¢—Ä–∞–µ–∫—Ç–æ—Ä–∏—è –¥–≤–∏–∂–µ–Ω–∏—è –æ—Ä–≥–∞–Ω–∏–∑–º–∞"""
    return A + b * np.cos(2 * np.pi * t)

def dx_dt(t, b):
    """–°–∫–æ—Ä–æ—Å—Ç—å –¥–≤–∏–∂–µ–Ω–∏—è –æ—Ä–≥–∞–Ω–∏–∑–º–∞"""
    return -2 * np.pi * b * np.sin(2 * np.pi * t)

# =============================================================================
# –ë–õ–û–ö 4: –§–£–ù–ö–¶–ò–Ø –§–ò–¢–ù–ï–°–ê
# =============================================================================

def fitness(params, env_params):
    """
    –§—É–Ω–∫—Ü–∏—è —Ñ–∏—Ç–Ω–µ—Å–∞ F(A, b) - –∏–Ω—Ç–µ–≥—Ä–∞–ª –∑–∞ —Å—É—Ç–∫–∏
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç -F(A, b) –¥–ª—è –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏–∏
    """
    A, b = params

    t = np.linspace(0, 1, Config.T_POINTS)
    integrand_values = []

    for t_i in t:
        x_t = x_trajectory(t_i, A, b)
        velocity = dx_dt(t_i, b)

        # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Ñ–∏—Ç–Ω–µ—Å–∞
        food_component = env_params["a"] * E(x_t, env_params)
        risk_component = env_params["gamma"] * P_x(x_t, env_params) * P_t(t_i)
        energy_component = env_params["beta"] * (velocity) ** 2
        other_component = env_params["lambda_Q"] * Q(x_t, env_params)

        integrand = food_component - risk_component - energy_component - other_component
        integrand_values.append(integrand)

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–µ—Ç–æ–¥ —Ç—Ä–∞–ø–µ—Ü–∏–π –≤–º–µ—Å—Ç–æ –ø—Ä–æ—Å—Ç–æ–≥–æ —Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏—è
    total_fitness = integrate.trapezoid(integrand_values, t)

    return -total_fitness  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º -F –¥–ª—è –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏–∏

# =============================================================================
# –ë–õ–û–ö 5: –ì–õ–û–ë–ê–õ–¨–ù–ê–Ø –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø
# =============================================================================

def find_global_optimum(env_params):
    """
    –ù–∞—Ö–æ–¥–∏—Ç –ì–õ–û–ë–ê–õ–¨–ù–´–ô –º–∞–∫—Å–∏–º—É–º F(A, b) –º–µ—Ç–æ–¥–æ–º –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–π —ç–≤–æ–ª—é—Ü–∏–∏
    """
    # –ë–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –∏ —Ñ–∏–∑–∏—á–µ—Å–∫–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
    bounds = [(-Config.D, 0), (0, Config.D/2)]

    # –ì–ª–æ–±–∞–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –º–µ—Ç–æ–¥–æ–º –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–π —ç–≤–æ–ª—é—Ü–∏–∏
    result = differential_evolution(
        fitness,
        bounds=bounds,
        args=(env_params,),
        strategy='best1bin',
        maxiter=100,
        popsize=15,
        tol=0.01,
        recombination=0.7,
        seed=42
    )

    if result.success:
        A_opt, b_opt = result.x
        F_opt = -result.fun  # F(A*, b*)
        return A_opt, b_opt, F_opt, result
    else:
        print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ì–ª–æ–±–∞–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω–µ —Å–æ—à–ª–∞—Å—å. –°–æ–æ–±—â–µ–Ω–∏–µ: {result.message}")
        # –†–µ–∑–µ—Ä–≤–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è - –∏—Å–ø–æ–ª—å–∑—É–µ–º –ª—É—á—à–µ–µ –Ω–∞–π–¥–µ–Ω–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ
        A_opt, b_opt = result.x
        F_opt = -result.fun
        return A_opt, b_opt, F_opt, result

# =============================================================================
# –ë–õ–û–ö 6: –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø –ü–û–í–ï–î–ï–ù–ò–Ø
# =============================================================================

def determine_behavior_class(b_optimal, grayzone_min, grayzone_max):
    """
    –ü—Ä–∏—Å–≤–∞–∏–≤–∞–µ—Ç –∫–ª–∞—Å—Å –ø–æ–≤–µ–¥–µ–Ω–∏—è —Å–æ–≥–ª–∞—Å–Ω–æ –Ω–∞–π–¥–µ–Ω–Ω–æ–º—É –∑–Ω–∞—á–µ–Ω–∏—é b*:
    ‚Ä¢ 0 ‚Äî –Ω–µ—Ç –º–∏–≥—Ä–∞—Ü–∏–∏, –µ—Å–ª–∏ b* < grayzone_min
    ‚Ä¢ 0.5 ‚Äî —Å–µ—Ä–∞—è –∑–æ–Ω–∞, –µ—Å–ª–∏ grayzone_min ‚â§ b* ‚â§ grayzone_max
    ‚Ä¢ 1 ‚Äî –µ—Å—Ç—å –º–∏–≥—Ä–∞—Ü–∏–∏, –µ—Å–ª–∏ b* > grayzone_max
    """
    if b_optimal < grayzone_min:
        return 0, "–ù–µ—Ç –º–∏–≥—Ä–∞—Ü–∏–∏"
    elif grayzone_min <= b_optimal <= grayzone_max:
        return 0.5, "–°–µ—Ä–∞—è –∑–æ–Ω–∞"
    else:
        return 1, "–ï—Å—Ç—å –º–∏–≥—Ä–∞—Ü–∏—è"

# =============================================================================
# –ë–õ–û–ö 7: –£–õ–£–ß–®–ï–ù–ù–ê–Ø –°–ò–°–¢–ï–ú–ê –ë–ê–õ–ê–ù–°–ò–†–û–í–ö–ò –ö–õ–ê–°–°–û–í
# =============================================================================

class BalancedDatasetGenerator:
    """–ö–ª–∞—Å—Å –¥–ª—è –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    
    def __init__(self):
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –¥–∏–∞–ø–∞–∑–æ–Ω—ã, –Ω–æ —Å–º–µ—â–∞–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞
        self.class_biases = {
            0: {  # –ù–µ—Ç –º–∏–≥—Ä–∞—Ü–∏–∏ - —Å–º–µ—â–∞–µ–º –≤ —Å—Ç–æ—Ä–æ–Ω—É –≤—ã—Å–æ–∫–æ–≥–æ —Ä–∏—Å–∫–∞/—Å—Ç–æ–∏–º–æ—Å—Ç–∏
                "sigma2_bias": 0.7,    # 70% –∫ –≤–µ—Ä—Ö–Ω–µ–π –≥—Ä–∞–Ω–∏—Ü–µ —Ä–∏—Å–∫–∞
                "beta_bias": 0.8,      # 80% –∫ –≤–µ—Ä—Ö–Ω–µ–π –≥—Ä–∞–Ω–∏—Ü–µ —Å—Ç–æ–∏–º–æ—Å—Ç–∏
                "sigma1_bias": 0.3,    # 30% –∫ –≤–µ—Ä—Ö–Ω–µ–π –≥—Ä–∞–Ω–∏—Ü–µ –µ–¥—ã (–º–µ–Ω—å—à–µ —Å—Ç–∏–º—É–ª–∞)
                "gamma_bias": 0.8      # 80% –∫ –≤–µ—Ä—Ö–Ω–µ–π –≥—Ä–∞–Ω–∏—Ü–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            },
            1: {  # –ï—Å—Ç—å –º–∏–≥—Ä–∞—Ü–∏—è - —Å–º–µ—â–∞–µ–º –≤ —Å—Ç–æ—Ä–æ–Ω—É –Ω–∏–∑–∫–æ–≥–æ —Ä–∏—Å–∫–∞/—Å—Ç–æ–∏–º–æ—Å—Ç–∏
                "sigma2_bias": 0.3,    # 30% –∫ –≤–µ—Ä—Ö–Ω–µ–π –≥—Ä–∞–Ω–∏—Ü–µ —Ä–∏—Å–∫–∞  
                "beta_bias": 0.2,      # 20% –∫ –≤–µ—Ä—Ö–Ω–µ–π –≥—Ä–∞–Ω–∏—Ü–µ —Å—Ç–æ–∏–º–æ—Å—Ç–∏
                "sigma1_bias": 0.7,    # 70% –∫ –≤–µ—Ä—Ö–Ω–µ–π –≥—Ä–∞–Ω–∏—Ü–µ –µ–¥—ã (–±–æ–ª—å—à–µ —Å—Ç–∏–º—É–ª–∞)
                "gamma_bias": 0.3      # 30% –∫ –≤–µ—Ä—Ö–Ω–µ–π –≥—Ä–∞–Ω–∏—Ü–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            },
            0.5: {  # –°–µ—Ä–∞—è –∑–æ–Ω–∞ - –±–∞–ª–∞–Ω—Å –≤–æ–∫—Ä—É–≥ —Å–µ—Ä–µ–¥–∏–Ω—ã
                "sigma2_bias": 0.5,    # 50% - —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
                "beta_bias": 0.5,      # 50% - —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
                "sigma1_bias": 0.5,    # 50% - —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
                "gamma_bias": 0.5      # 50% - —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
            }
        }
    
    def generate_balanced_dataset(self, num_samples=1000, save_path="migration_dataset_balanced.pkl"):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
        dataset = self._initialize_dataset()
        
        print(f"üéØ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏: {num_samples} –æ–±—Ä–∞–∑—Ü–æ–≤")
        target_counts = self._calculate_target_distribution(num_samples)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞
        for target_class in [0, 0.5, 1]:
            self._generate_class_samples(target_class, target_counts[target_class], dataset)
        
        return self._finalize_dataset(dataset, save_path)
    
    def _generate_class_samples(self, target_class, target_count, dataset):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞"""
        print(f"\nüìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–ª–∞—Å—Å–∞ {target_class}...")
        generated = 0
        attempts = 0
        max_attempts = target_count * 20
        
        while generated < target_count and attempts < max_attempts:
            attempts += 1
            
            if attempts % 20 == 0:
                success_rate = (generated / attempts) * 100 if attempts > 0 else 0
                print(f"  –ü–æ–ø—ã—Ç–∫–∞ {attempts}, —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {generated}/{target_count} (—É—Å–ø–µ—Ö: {success_rate:.1f}%)")
            
            env = self._apply_class_bias(target_class, generate_environment())
            A_opt, b_opt, F_opt, result = find_global_optimum(env)
            
            if result.success:
                behavior_class, behavior_name = determine_behavior_class(
                    b_opt, env["grayzone_min"], env["grayzone_max"])
                
                if behavior_class == target_class:
                    self._add_sample_to_dataset(dataset, env, A_opt, b_opt, F_opt, behavior_class, behavior_name, result)
                    generated += 1
                elif attempts % 25 == 0:
                    # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞: –ø–æ—á–µ–º—É –Ω–µ –ø–æ–ª—É—á–∏–ª—Å—è –Ω—É–∂–Ω—ã–π –∫–ª–∞—Å—Å
                    print(f"    –ü–æ–ª—É—á–µ–Ω –∫–ª–∞—Å—Å {behavior_class} –≤–º–µ—Å—Ç–æ {target_class}, b*={b_opt:.2f}")
                    print(f"    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: sigma1={env['sigma1']:.2f}, sigma2={env['sigma2']:.2f}, beta={env['beta']:.2e}, gamma={env['gamma']:.2f}")
        
        print(f"  ‚úÖ –ö–ª–∞—Å—Å {target_class}: {generated}/{target_count} (–ø–æ–ø—ã—Ç–æ–∫: {attempts})")
    
    def _apply_class_bias(self, target_class, env):
        """–ü—Ä–∏–º–µ–Ω—è–µ–º —Å–º–µ—â–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è —Ü–µ–ª–µ–≤–æ–≥–æ –∫–ª–∞—Å—Å–∞, —Å–æ—Ö—Ä–∞–Ω—è—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –¥–∏–∞–ø–∞–∑–æ–Ω—ã"""
        biases = self.class_biases[target_class]
        
        # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –¥–∏–∞–ø–∞–∑–æ–Ω—ã
        original_ranges = {
            "sigma1": (0.25, 8.61),
            "sigma2": (0.003, 8.99), 
            "beta": (1e-9, 0.001),
            "gamma": (0.001, 1000)
        }
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Å–º–µ—â–µ–Ω–∏–µ –≤ —Ä–∞–º–∫–∞—Ö –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤
        for param, bias in biases.items():
            param_name = param.replace("_bias", "")
            low, high = original_ranges[param_name]
            
            if bias < 0.5:
                # –°–º–µ—â–∞–µ–º –∫ –Ω–∏–∂–Ω–µ–π –≥—Ä–∞–Ω–∏—Ü–µ
                new_low = low
                new_high = low + (high - low) * (bias * 2)
            else:
                # –°–º–µ—â–∞–µ–º –∫ –≤–µ—Ä—Ö–Ω–µ–π –≥—Ä–∞–Ω–∏—Ü–µ  
                new_low = low + (high - low) * ((bias - 0.5) * 2)
                new_high = high
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –≤ —Å–º–µ—â–µ–Ω–Ω–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ
            if param_name == "beta":  # –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–∏–π –º–∞—Å—à—Ç–∞–± –¥–ª—è beta
                log_low = np.log10(new_low)
                log_high = np.log10(new_high)
                env[param_name] = 10 ** np.random.uniform(log_low, log_high)
            else:
                env[param_name] = np.random.uniform(new_low, new_high)
        
        return env

    # –û—Å—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –æ—Å—Ç–∞—é—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π...
    def _initialize_dataset(self):
        return {
            'features': [], 'targets': [], 'behavior_names': [],
            'env_params': [], 'optimization_info': []
        }
    
    def _calculate_target_distribution(self, num_samples):
        samples_per_class = num_samples // 3
        remaining = num_samples % 3
        return {
            0: samples_per_class + (1 if remaining >= 1 else 0),
            0.5: samples_per_class + (1 if remaining >= 2 else 0),
            1: samples_per_class
        }
    
    def _add_sample_to_dataset(self, dataset, env, A_opt, b_opt, F_opt, behavior_class, behavior_name, result):
        features = [env["sigma1"], env["xi1"], env["sigma2"], env["xi2"],
                   env["xi3"], env["xi4"], env["eta1"], env["eta2"], env["c3"], env["c4"]]
        
        dataset['features'].append(features)
        dataset['targets'].append([A_opt, b_opt, F_opt, behavior_class])
        dataset['behavior_names'].append(behavior_name)
        dataset['env_params'].append(env)
        dataset['optimization_info'].append({
            'success': result.success, 'message': result.message,
            'nfev': result.nfev, 'nit': result.nit
        })
    
    def _finalize_dataset(self, dataset, save_path):
        if len(dataset['features']) > 0:
            dataset['features'] = np.array(dataset['features'])
            dataset['targets'] = np.array(dataset['targets'])
        else:
            print("‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ: –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ –æ–±—Ä–∞–∑—Ü–∞!")
            dataset['features'] = np.array([])
            dataset['targets'] = np.array([])
        
        with open(save_path, 'wb') as f:
            pickle.dump(dataset, f)
        
        csv_path = save_path.replace('.pkl', '.csv')
        save_dataset_csv(dataset, csv_path)
        
        print(f"\nüéâ –î–∞—Ç—Å–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω:")
        print(f"   üìÅ Pickle: {save_path}")
        print(f"   üìÅ CSV: {csv_path}")
        
        return dataset

# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞
balanced_generator = BalancedDatasetGenerator()

def generate_balanced_dataset(num_samples=1000, save_path="migration_dataset_balanced.pkl"):
    """–£–ª—É—á—à–µ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    return balanced_generator.generate_balanced_dataset(num_samples, save_path)

# =============================================================================
# –ë–õ–û–ö 8: –ë–ê–ó–û–í–ê–Ø –ì–ï–ù–ï–†–ê–¶–ò–Ø –í–´–ë–û–†–ö–ò
# =============================================================================

def generate_training_dataset(num_samples=1000, save_path="migration_dataset.pkl"):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≤—ã–±–æ—Ä–∫—É –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏
    –¢–æ–ª—å–∫–æ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å—Ä–µ–¥—ã –≤ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö, –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –æ—Ä–≥–∞–Ω–∏–∑–º–∞ –∏—Å–∫–ª—é—á–µ–Ω—ã
    """

    dataset = {
        'features': [],      # –¢–æ–ª—å–∫–æ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å—Ä–µ–¥—ã
        'targets': [],       # –¶–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ [A_opt, b_opt, fitness, class]
        'behavior_names': [], 
        'env_params': [],    
        'optimization_info': []
    }

    print(f"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è {num_samples} –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–∞–Ω–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–º –≥–ª–æ–±–∞–ª—å–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏...")
    print("–í –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤–∫–ª—é—á–µ–Ω—ã –¢–û–õ–¨–ö–û –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å—Ä–µ–¥—ã (–∏—Å–∫–ª—é—á–µ–Ω—ã a, gamma, beta, lambda_Q)")

    successful_optimizations = 0

    for i in range(num_samples):
        if (i + 1) % 100 == 0:
            print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {i + 1}/{num_samples} –æ–±—Ä–∞–∑—Ü–æ–≤")

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ä–µ–¥—ã
        env = generate_environment()

        # –ì–ª–æ–±–∞–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
        A_opt, b_opt, F_opt, result = find_global_optimum(env)

        if result.success:
            successful_optimizations += 1

        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∞ –ø–æ–≤–µ–¥–µ–Ω–∏—è
        behavior_class, behavior_name = determine_behavior_class(
            b_opt, env["grayzone_min"], env["grayzone_max"])

        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–¢–û–õ–¨–ö–û –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å—Ä–µ–¥—ã)
        features = [
            env["sigma1"], env["xi1"], env["sigma2"], env["xi2"],
            env["xi3"], env["xi4"], env["eta1"], env["eta2"],
            env["c3"], env["c4"]
        ]

        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
        targets = [A_opt, b_opt, F_opt, behavior_class]

        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        opt_info = {
            'success': result.success,
            'message': result.message,
            'nfev': result.nfev,
            'nit': result.nit
        }

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        dataset['features'].append(features)
        dataset['targets'].append(targets)
        dataset['behavior_names'].append(behavior_name)
        dataset['env_params'].append(env)
        dataset['optimization_info'].append(opt_info)

    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ numpy –º–∞—Å—Å–∏–≤—ã
    dataset['features'] = np.array(dataset['features'])
    dataset['targets'] = np.array(dataset['targets'])

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    success_rate = successful_optimizations / num_samples * 100
    print(f"\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≥–ª–æ–±–∞–ª—å–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏:")
    print(f"–£—Å–ø–µ—à–Ω—ã—Ö –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π: {successful_optimizations}/{num_samples} ({success_rate:.1f}%)")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ pickle
    with open(save_path, 'wb') as f:
        pickle.dump(dataset, f)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV
    csv_path = save_path.replace('.pkl', '.csv')
    save_dataset_csv(dataset, csv_path)

    return dataset

# =============================================================================
# –ë–õ–û–ö 9: –ê–ù–ê–õ–ò–ó –ò –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –î–ê–ù–ù–´–•
# =============================================================================

def analyze_dataset(dataset):
    """
    –ê–Ω–∞–ª–∏–∑ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
    """
    print("\n" + "="*60)
    print("–ê–ù–ê–õ–ò–ó –î–ê–¢–ê–°–ï–¢–ê")
    print("="*60)

    features = dataset['features']
    targets = dataset['targets']
    behavior_names = dataset['behavior_names']
    optimization_info = dataset['optimization_info']

    print(f"–†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞: {len(features)} –æ–±—Ä–∞–∑—Ü–æ–≤")
    print(f"–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {features.shape}")
    print(f"–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö: {targets.shape}")

    # –ê–Ω–∞–ª–∏–∑ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    success_count = sum(1 for info in optimization_info if info['success'])
    print(f"–£—Å–ø–µ—à–Ω—ã—Ö –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π: {success_count}/{len(optimization_info)} ({success_count/len(optimization_info)*100:.1f}%)")

    # –ê–Ω–∞–ª–∏–∑ –∫–ª–∞—Å—Å–æ–≤ –ø–æ–≤–µ–¥–µ–Ω–∏—è
    behavior_classes = targets[:, 3]
    unique_classes, class_counts = np.unique(behavior_classes, return_counts=True)

    print(f"\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –ø–æ–≤–µ–¥–µ–Ω–∏—è:")
    for class_val, count in zip(unique_classes, class_counts):
        class_samples = [name for i, name in enumerate(behavior_names)
                        if behavior_classes[i] == class_val]
        class_name = class_samples[0] if class_samples else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
        percentage = count / len(behavior_classes) * 100
        print(f"  –ö–ª–∞—Å—Å {class_val} ({class_name}): {count} samples ({percentage:.1f}%)")

    print(f"\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º:")
    print(f"  A_optimal: mean={targets[:, 0].mean():.2f}, std={targets[:, 0].std():.2f}")
    print(f"  b_optimal: mean={targets[:, 1].mean():.2f}, std={targets[:, 1].std():.2f}")
    print(f"  fitness_optimal: mean={targets[:, 2].mean():.2f}, std={targets[:, 2].std():.2f}")

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∏—Ç–µ—Ä–∞—Ü–∏—è–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    nfev_values = [info['nfev'] for info in optimization_info]
    nit_values = [info['nit'] for info in optimization_info]
    print(f"\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏:")
    print(f"  –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ü–µ–Ω–æ–∫ —Ñ—É–Ω–∫—Ü–∏–∏: {np.mean(nfev_values):.1f}")
    print(f"  –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π: {np.mean(nit_values):.1f}")

def plot_dataset_distribution(dataset):
    """
    –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ
    """
    targets = dataset['targets']
    behavior_classes = targets[:, 3]

    fig, axes = plt.subplots(2, 2, figsize=(15, 12))

    # 1. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –ø–æ–≤–µ–¥–µ–Ω–∏—è
    unique_classes, class_counts = np.unique(behavior_classes, return_counts=True)
    colors = {0: 'red', 0.5: 'orange', 1: 'green'}
    bar_colors = [colors[cls] for cls in unique_classes]

    axes[0, 0].bar(unique_classes, class_counts, color=bar_colors, alpha=0.7, width=0.3)
    axes[0, 0].set_xlabel('–ö–ª–∞—Å—Å –ø–æ–≤–µ–¥–µ–Ω–∏—è')
    axes[0, 0].set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤')
    axes[0, 0].set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –ø–æ–≤–µ–¥–µ–Ω–∏—è\n(–ì–ª–æ–±–∞–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è)')
    axes[0, 0].set_xticks([0, 0.5, 1])

    # 2. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –∞–º–ø–ª–∏—Ç—É–¥—ã b_optimal
    axes[0, 1].hist(targets[:, 1], bins=30, alpha=0.7, color='blue', edgecolor='black')
    axes[0, 1].axvline(x=Config.GRAYZONE_MIN, color='red', linestyle='--', label='–ì—Ä–∞–Ω–∏—Ü–∞ —Å–µ—Ä–æ–π –∑–æ–Ω—ã (min)')
    axes[0, 1].axvline(x=Config.GRAYZONE_MAX, color='red', linestyle='--', label='–ì—Ä–∞–Ω–∏—Ü–∞ —Å–µ—Ä–æ–π –∑–æ–Ω—ã (max)')
    axes[0, 1].set_xlabel('–û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è –∞–º–ø–ª–∏—Ç—É–¥–∞ b*')
    axes[0, 1].set_ylabel('–ß–∞—Å—Ç–æ—Ç–∞')
    axes[0, 1].set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –∞–º–ø–ª–∏—Ç—É–¥—ã –º–∏–≥—Ä–∞—Ü–∏–∏')
    axes[0, 1].legend()

    # 3. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –≥–ª—É–±–∏–Ω—ã A_optimal
    axes[1, 0].hist(targets[:, 0], bins=30, alpha=0.7, color='purple', edgecolor='black')
    axes[1, 0].set_xlabel('–û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞ A*')
    axes[1, 0].set_ylabel('–ß–∞—Å—Ç–æ—Ç–∞')
    axes[1, 0].set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –≥–ª—É–±–∏–Ω—ã')

    # 4. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ–∏—Ç–Ω–µ—Å–∞
    axes[1, 1].hist(targets[:, 2], bins=30, alpha=0.7, color='green', edgecolor='black')
    axes[1, 1].set_xlabel('–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ñ–∏—Ç–Ω–µ—Å F(A*, b*)')
    axes[1, 1].set_ylabel('–ß–∞—Å—Ç–æ—Ç–∞')
    axes[1, 1].set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π —Ñ–∏—Ç–Ω–µ—Å–∞')

    plt.tight_layout()
    plt.show()

def save_dataset_csv(dataset, csv_path="migration_dataset.csv"):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç –≤ CSV —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è Excel"""
    with open(csv_path, 'w', newline='', encoding='utf-8-sig') as f:
        writer = csv.writer(f, delimiter=';')

        headers = [
            'sigma1', 'xi1', 'sigma2', 'xi2', 'xi3', 'xi4', 'eta1', 'eta2',
            'c3', 'c4', 'A_optimal', 'b_optimal', 'fitness_optimal', 'behavior_class', 'behavior_name'
        ]
        writer.writerow(headers)

        for i in range(len(dataset['features'])):
            row = (
                list(dataset['features'][i]) +
                list(dataset['targets'][i]) +
                [dataset['behavior_names'][i]]
            )
            writer.writerow(row)

    print(f"–î–∞—Ç–∞—Å–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ CSV (–¥–ª—è Excel): {csv_path}")
    print("–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –í –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤–∫–ª—é—á–µ–Ω—ã —Ç–æ–ª—å–∫–æ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å—Ä–µ–¥—ã (10 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)")

# =============================================================================
# –ë–õ–û–ö 10: –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –ì–õ–û–ë–ê–õ–¨–ù–û–ô –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò
# =============================================================================

def demonstrate_global_optimization():
    """
    –î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç —Ä–∞–±–æ—Ç—É –≥–ª–æ–±–∞–ª—å–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –Ω–∞ –æ–¥–Ω–æ–º –ø—Ä–∏–º–µ—Ä–µ
    """
    print("–î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –ì–õ–û–ë–ê–õ–¨–ù–û–ô –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò")
    print("=" * 50)

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤–æ–π —Å—Ä–µ–¥—ã
    env = generate_environment()

    print("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å—Ä–µ–¥—ã:")
    for key, value in env.items():
        if key not in ['grayzone_min', 'grayzone_max']:
            print(f"  {key}: {value:.4f}")

    # –ì–ª–æ–±–∞–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
    print("\n–ó–∞–ø—É—Å–∫ –≥–ª–æ–±–∞–ª—å–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏...")
    A_opt, b_opt, F_opt, result = find_global_optimum(env)

    print(f"\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≥–ª–æ–±–∞–ª—å–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏:")
    print(f"  A* = {A_opt:.4f}")
    print(f"  b* = {b_opt:.4f}")
    print(f"  F(A*, b*) = {F_opt:.4f}")
    print(f"  –£—Å–ø–µ—Ö: {result.success}")
    print(f"  –°–æ–æ–±—â–µ–Ω–∏–µ: {result.message}")
    print(f"  –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π: {result.nit}")
    print(f"  –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ü–µ–Ω–æ–∫ —Ñ—É–Ω–∫—Ü–∏–∏: {result.nfev}")

    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∞ –ø–æ–≤–µ–¥–µ–Ω–∏—è
    behavior_class, behavior_name = determine_behavior_class(
        b_opt, env["grayzone_min"], env["grayzone_max"])

    print(f"  –ö–ª–∞—Å—Å –ø–æ–≤–µ–¥–µ–Ω–∏—è: {behavior_class} ({behavior_name})")

    return env, A_opt, b_opt, F_opt, result

# =============================================================================
# –ë–õ–û–ö 11: –û–°–ù–û–í–ù–ê–Ø –ü–†–û–ì–†–ê–ú–ú–ê
# =============================================================================

def main():
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞
    """
    print("–ì–ï–ù–ï–†–ê–¶–ò–Ø –î–ê–¢–ê–°–ï–¢–ê –° –ì–õ–û–ë–ê–õ–¨–ù–û–ô –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ï–ô")
    print("=" * 60)
    print("–í–ê–ñ–ù–û: –í –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤–∫–ª—é—á–µ–Ω—ã –¢–û–õ–¨–ö–û –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å—Ä–µ–¥—ã (10 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)")
    print("–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –æ—Ä–≥–∞–Ω–∏–∑–º–∞ (a, gamma, beta, lambda_Q) –∏—Å–∫–ª—é—á–µ–Ω—ã –∏–∑ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")

    # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –Ω–∞ –æ–¥–Ω–æ–º –ø—Ä–∏–º–µ—Ä–µ
    demonstrate_global_optimization()

    print("\n" + "=" * 60)

    # –í—ã–±–æ—Ä —Ç–∏–ø–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    print("–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:")
    print("1 - –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)")
    print("2 - –ë–∞–∑–æ–≤–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è")
    
    choice = input("–í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä (1 –∏–ª–∏ 2): ").strip()
    
    if choice == "1":
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
        dataset = generate_balanced_dataset(
            num_samples=30,  # 10 –Ω–∞ –∫–ª–∞—Å—Å
            save_path="migration_dataset_balanced.pkl"
        )
    else:
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –±–∞–∑–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
        dataset = generate_training_dataset(
            num_samples=30,
            save_path="migration_dataset_base.pkl"
        )

    # –ê–Ω–∞–ª–∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞
    analyze_dataset(dataset)

    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
    plot_dataset_distribution(dataset)

    # –í—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –¥–∞–Ω–Ω—ã—Ö
    print("\n–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞:")
    print(f"–ü—Ä–∏–∑–Ω–∞–∫–∏ (features): –º–∞—Å—Å–∏–≤ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ {dataset['features'].shape}")
    print(f"  –°—Ç–æ–ª–±—Ü—ã: sigma1, xi1, sigma2, xi2, xi3, xi4, eta1, eta2, c3, c4")
    print(f"  –ò–°–ö–õ–Æ–ß–ï–ù–´: a, gamma, beta, lambda_Q")
    print(f"–¶–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ (targets): –º–∞—Å—Å–∏–≤ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ {dataset['targets'].shape}")
    print(f"  –°—Ç–æ–ª–±—Ü—ã: A_optimal, b_optimal, fitness_optimal, behavior_class")

if __name__ == "__main__":
    main()